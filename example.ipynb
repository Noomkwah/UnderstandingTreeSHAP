{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of TreeSHAP\n",
        "*Understanding TreeSHAP: A complete tutorial*"
      ],
      "metadata": {
        "id": "UO1_Oqkr9RjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "X0CQVTN29xQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpjBzrs5J24i",
        "outputId": "b7aaf926-08ef-4ac8-e7da-cfd90232688f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.43.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (532 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.9/532.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.43.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Okhw0D2mvTJ0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code of TreeSHAP from the article"
      ],
      "metadata": {
        "id": "OkrEDKA092mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def UNWIND_weights(weights_wound, ones_ki, zeros_ki):\n",
        "  Dk = len(weights_wound) - 1\n",
        "  weights_unwound = np.zeros(Dk)\n",
        "\n",
        "  # First case\n",
        "  if ones_ki == 0:\n",
        "    for h in range(0, Dk):\n",
        "      weights_unwound[h] = (Dk + 1)/(Dk - h) * weights_wound[h] / zeros_ki\n",
        "\n",
        "  # Second case\n",
        "  else:\n",
        "    omega = np.zeros(Dk+1)\n",
        "    omega[Dk] = weights_wound[Dk]\n",
        "\n",
        "    for h in range(Dk-1, -1, -1): # h = Dk-1, Dk-2, ..., 1, 0\n",
        "      weights_unwound[h] = omega[h+1] * (Dk+1)/(h+1) * 1/ones_ki\n",
        "      omega[h] = weights_wound[h] - (Dk-h)/(Dk+1) * weights_unwound[h] * zeros_ki\n",
        "\n",
        "  return list(weights_unwound)\n",
        "\n",
        "def UNWIND(features_wound, ones_wound, zeros_wound, weights_wound, i):\n",
        "\n",
        "  ## UNWIND_weights ##\n",
        "  weights_unwound = UNWIND_weights(weights_wound, ones_wound[i], zeros_wound[i])\n",
        "\n",
        "  ## UNWIND features_wound, ones_wound, zeros_wound ##\n",
        "  features_unwound = list(np.delete(features_wound, i))\n",
        "  ones_unwound = list(np.delete(ones_wound, i))\n",
        "  zeros_unwound = list(np.delete(zeros_wound, i))\n",
        "\n",
        "  return features_unwound, ones_unwound, zeros_unwound, weights_unwound\n",
        "\n",
        "def EXTEND(features_P, ones_P, zeros_P, weights_P, feature_e, one_e, zero_e):\n",
        "\n",
        "  # We save the encountered feature, the condition and the proportion\n",
        "  features_Pe = features_P + [feature_e]\n",
        "  ones_Pe = ones_P + [one_e]\n",
        "  zeros_Pe = zeros_P + [zero_e]\n",
        "\n",
        "  D = len(weights_P)-1 # Number of distinct features met uptill now\n",
        "\n",
        "  # First case: weights_P is empty, we leave 'All Data' node\n",
        "  if not weights_P:\n",
        "    weights_Pe = [1]\n",
        "\n",
        "  # Second case: weights_P is not empty\n",
        "  else:\n",
        "    weights_P_ = weights_P + [0] # We add w[D+1 , P] = 0\n",
        "\n",
        "    # We compute the new weights\n",
        "    weights_Pe = np.zeros(D+2)\n",
        "    weights_Pe[0] = (D+1)/(D+2) * weights_P_[0] * zero_e\n",
        "    for h in range(0, D+1):\n",
        "      weights_Pe[h+1] += (h+1)/(D+2) * weights_P_[h] * one_e\n",
        "      weights_Pe[h+1] += (D-h)/(D+2) * weights_P_[h+1] * zero_e\n",
        "\n",
        "  return features_Pe, ones_Pe, zeros_Pe, list(weights_Pe)\n",
        "\n",
        "\n",
        "def treeSHAP(tree, x):\n",
        "  phi = np.zeros(len(x)) # We initialize the SHAP values at 0\n",
        "\n",
        "  def RECURSE(node, features_, ones_, zeros_, weights_, feature_e, one_e, zero_e):\n",
        "\n",
        "    args = (features_, ones_, zeros_, weights_, feature_e, one_e, zero_e)\n",
        "    features_, ones_, zeros_, weights_ = EXTEND(*args)\n",
        "\n",
        "    if node.is_leaf: # Case 1: the node is a leaf\n",
        "      for i in range(1, len(weights_)):\n",
        "        phi[features_[i]] += sum(UNWIND_weights(weights_, ones_[i], zeros_[i])) * (ones_[i] - zeros_[i]) * node.value\n",
        "\n",
        "    else: # Case 2: the node is internal\n",
        "      # We establish which child is hot and which one is cold\n",
        "      if x[node.feature] <= node.threshold:\n",
        "        hot_child, cold_child = node.left_child, node.right_child\n",
        "      else:\n",
        "        cold_child, hot_child = node.left_child, node.right_child\n",
        "\n",
        "      feature_e = node.feature # Identical for both hot and cold children\n",
        "      hot_one_e = 1 # By definition of the hot child\n",
        "      cold_one_e = 0\n",
        "      hot_zero_e = hot_child.n_samples / node.n_samples\n",
        "      cold_zero_e = cold_child.n_samples / node.n_samples\n",
        "\n",
        "      # We check whether feature_e has already been encountered\n",
        "      feature_e_indexes = np.where(features_==feature_e)[0]\n",
        "      if len(feature_e_indexes) > 0: # the feature has already been encountered\n",
        "        i = feature_e_indexes[0]\n",
        "        hot_one_e *= ones_[i]\n",
        "        hot_zero_e *= zeros_[i]\n",
        "        cold_zero_e *= zeros_[i]\n",
        "\n",
        "        # UNWIND to delete feature_e\n",
        "        args = (features_, ones_, zeros_, weights_, i)\n",
        "        features_, ones_, zeros_, weights_ = UNWIND(*args)\n",
        "\n",
        "      # Final recursive calls\n",
        "      RECURSE(hot_child, features_, ones_, zeros_, weights_, feature_e, hot_one_e, hot_zero_e)\n",
        "      RECURSE(cold_child, features_, ones_, zeros_, weights_, feature_e, cold_one_e, cold_zero_e)\n",
        "\n",
        "  # We call RECURSE on the root of the tree,\n",
        "  # by setting feature_e = -1 to indicate there is no feature on the first edge\n",
        "  RECURSE(tree.root, [], [], [], [], -1, 1, 1)\n",
        "\n",
        "  return phi"
      ],
      "metadata": {
        "id": "VXmZdTnsvtap"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tests on different decision trees"
      ],
      "metadata": {
        "id": "XJGE98vp-eid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first implement a custom decision tree."
      ],
      "metadata": {
        "id": "cEOSkkrGB01u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Leaf():\n",
        "\n",
        "  def __init__(self, value=None, n_samples=None, name=None):\n",
        "    self.value = value\n",
        "    self.n_samples = n_samples\n",
        "    self.is_leaf = True\n",
        "    self.name = name # Useful for debugging\n",
        "\n",
        "  def predict(self, X):\n",
        "    return self.value\n",
        "\n",
        "class Node():\n",
        "\n",
        "  def __init__(self, left_child=None, right_child=None, feature=None, threshold=None, value=None, name=None):\n",
        "    self.left_child = left_child\n",
        "    self.right_child = right_child\n",
        "    self.feature = feature\n",
        "    self.threshold = threshold\n",
        "    self.value = value\n",
        "    self.n_samples = None\n",
        "    self.name = name # Useful for debugging\n",
        "    self.is_leaf = False\n",
        "\n",
        "    self.root = self # To keep along with the notation of the article\n",
        "\n",
        "  def predict(self, X):\n",
        "    if X[self.feature] <= self.threshold:\n",
        "      return self.left_child.predict(X)\n",
        "    else:\n",
        "      return self.right_child.predict(X)\n",
        "\n",
        "\n",
        "def tree_from_dict(tree_dict, i=0): # Useful later on.\n",
        "\n",
        "  if tree_dict['features'][i] == -2: # We are on a leaf\n",
        "    value = tree_dict[\"values\"][i][0] # We unpack the value\n",
        "    n_samples = tree_dict[\"node_sample_weight\"][i]\n",
        "    return Leaf(value=value, n_samples=n_samples)\n",
        "\n",
        "  else:\n",
        "    node = Node()\n",
        "    node.feature = tree_dict['features'][i]\n",
        "    node.threshold = tree_dict['thresholds'][i]\n",
        "    node.value = tree_dict['values'][i][0]\n",
        "    node.n_samples = tree_dict[\"node_sample_weight\"][i]\n",
        "\n",
        "    node.left_child = tree_from_dict(tree_dict, tree_dict['children_left'][i])\n",
        "    node.right_child = tree_from_dict(tree_dict, tree_dict['children_right'][i])\n",
        "\n",
        "    return node"
      ],
      "metadata": {
        "id": "QWPO5TGfMUhz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision tree from the article"
      ],
      "metadata": {
        "id": "uBTVsRLU-k4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # children_left[i] corresponds to the index of the left child of node i. children_left[i] = -1 means i does not have a left child\n",
        " # features[i] = -2 means there is no condition (hence, i is a leaf). Also we adpoted the following indexation: {'age': 0, 'weight': 1, 'height': 2, 'bodyfat': 3}\n",
        "children_left = np.array([1, 2, -1, 4, -1, -1, 7, 8, -1, -1, -1])\n",
        "children_right = np.array([6, 3, -1, 5, -1, -1, 10, 9, -1, -1, -1])\n",
        "features = np.array([0, 1, -2, 2, -2, -2, 3, 0, -2, -2, -2])\n",
        "thresholds = np.array([50, 100, -2, 180, -2, -2, 30, 70, -2, -2, -2])\n",
        "values = np.array([0.41, 0.32666666666666667, 0.2, 0.8333333333333334, 0.9, 0.7, 0.66, 0.4666666666666667, 0.4, 0.6, 0.95]) # Values of internal nodes are weighted average of the values of their children.\n",
        "node_sample_weight = np.array([100, 75, 60, 15, 10, 5, 25, 15, 10, 5, 10])\n",
        "\n",
        "# Formatting the custom tree\n",
        "tree_dict = {\n",
        "    \"children_left\": children_left,\n",
        "    \"children_right\": children_right,\n",
        "    \"children_default\": children_right.copy(), # We write it to keep along with the formatting of the package shap.\n",
        "    \"features\": features,\n",
        "    \"thresholds\": thresholds,\n",
        "    \"values\": np.reshape(values,(-1,1)), # Same remark.\n",
        "    \"node_sample_weight\": node_sample_weight\n",
        "}\n",
        "model = {\"trees\": [tree_dict]}"
      ],
      "metadata": {
        "id": "FOdrfJip-rkK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom samples: x = (age in years, weight in kg, height in cm, bodyfat in %)\n",
        "x_1 = (56, 93, 187, 37) # Gérard, from the article\n",
        "x_2 = (43, 25, 157, 16)\n",
        "x_3 = (47, 117, 175, 24)\n",
        "x_4 = (34, 101, 187, 23)\n",
        "x_5 = (71, 75, 178, 27)\n",
        "x_6 = (60, 100, 160, 25)\n",
        "L = [x_1, x_2, x_3, x_4, x_5, x_6]"
      ],
      "metadata": {
        "id": "7b6trkvTBkEt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our implementation of TreeSHAP\n",
        "tree = tree_from_dict(tree_dict) # Tree from the article\n",
        "print(f'Homemade SHAP values: {treeSHAP(tree, x_1)}')\n",
        "\n",
        "# Implementation of TreeSHAP from package shap\n",
        "explainer = shap.TreeExplainer(model)\n",
        "print(f'Actual SHAP values: {explainer.shap_values(np.array(x_1))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yb-7wHoDTVX",
        "outputId": "a08946fa-3a46-433c-eda3-3bdb54048283"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Homemade SHAP values: [ 0.38958333 -0.04416667 -0.00666667  0.20125   ]\n",
            "Actual SHAP values: [ 0.38958333 -0.04416667 -0.00666667  0.20125   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Another example, not from the article"
      ],
      "metadata": {
        "id": "S9waK14gFv89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_diabetes(return_X_y=True)\n",
        "regressor = DecisionTreeRegressor(random_state=0, max_depth=7)\n",
        "regressor.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "07qTnXRwyJpi",
        "outputId": "d41b0d6c-fcbb-414c-da51-b36151e30eb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=7, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=7, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=7, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Formatting the custom tree\n",
        "tree_dict_bis = {\n",
        "    \"children_left\": regressor.tree_.children_left,\n",
        "    \"children_right\": regressor.tree_.children_right,\n",
        "    \"children_default\": regressor.tree_.children_right.copy(), # We write it to keep along with the formatting of the package shap.\n",
        "    \"features\": regressor.tree_.feature,\n",
        "    \"thresholds\": regressor.tree_.threshold,\n",
        "    \"values\": np.reshape(regressor.tree_.value,(-1,1)),\n",
        "    \"node_sample_weight\": regressor.tree_.n_node_samples\n",
        "}\n",
        "model_bis = {\"trees\": [tree_dict_bis]}"
      ],
      "metadata": {
        "id": "5rufc0pWGB44"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our implementation of TreeSHAP\n",
        "tree_bis = tree_from_dict(tree_dict_bis) # Tree from the article\n",
        "print(f'Homemade SHAP values: {treeSHAP(tree_bis, X[0])}')\n",
        "\n",
        "# Implementation of TreeSHAP from package shap\n",
        "explainer = shap.TreeExplainer(model_bis)\n",
        "print(f'Actual SHAP values: {explainer.shap_values(X[0])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0gvnvbjGc0l",
        "outputId": "730f4e8f-df44-4ddf-f9aa-50171a18102f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Homemade SHAP values: [-0.05576818 -1.58100166 26.26286909 16.29865298  3.54881159  0.09810506\n",
            "  0.29857304  0.36819254 17.79555359 -2.85977991]\n",
            "Actual SHAP values: [-0.05576818 -1.58100166 26.26286909 16.29865298  3.54881159  0.09810506\n",
            "  0.29857304  0.36819254 17.79555359 -2.85977991]\n"
          ]
        }
      ]
    }
  ]
}